---
title: "Data Mining Project"
author: "Nadine Fares, Leyang Shi, Bai Xue"
date: "12/8/2017"
output: 
  html_document:
    toc: true
    toc_depth: 4
    theme: lumen
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Librarys
```{r, message = FALSE}
library(ggplot2)
library(plyr)
library(ISLR)
library(MASS)
library(knitr)
library(gam)
library(readr)
library(glmnet)
library(rmarkdown)
library(rpart)
library(klaR) 
library(leaps) 
library(partykit)
library(randomForest)
library(dplyr)
library(pROC)

```

#Question 1 - What are the Key Determinents of School Success?

## Methods
###Cleaning and transforming the Data
##### Read in data and read convert values to 0/1/NA
```{r, warning=FALSE, message = FALSE}
#linear regression
elementary <- read_csv("elementary.csv")

middle <- read_csv("middle.csv")

high <- read_csv("high.csv")
```

#####Create Transformation Functions
```{r}
#to transform and clean API
APITransform <- function(dataset){
  if(is.data.frame(dataset)){
  dataset <- transform(dataset, 
                  API = mapvalues(API, c("Low","High","?"), 
                                     c(0, 1, NA)))
   #Change ? to NA
   dataset[dataset == "?"] <- NA
      
  #This removes rows where API has null values
  dataset <- dataset[-which(is.na(dataset$API)), ]
  return(dataset)
  }
}

#Categorical Changes
 ChangeCategorical <-function(dataset){
     if(is.data.frame(dataset)){
        
       #Change to numeric 
        dataset$ACS_CORE <- as.numeric(dataset$ACS_CORE)
      
       #Find the median(for ACS_CORE)
        median.ASC<- median(dataset$ACS_CORE, na.rm = TRUE)
        max.ASC <- max(dataset$ACS_CORE,na.rm = TRUE)
        dataset$ACS_CORE <- cut(dataset$ACS_CORE, c(1, median.ASC + 1, max.ASC),labels
                                     = FALSE)
        dataset$ACS_CORE[is.na(dataset$ACS_CORE)] <- 3
      
       #change ACS_CORE to categorical
        dataset$ACS_CORE <- factor(dataset$ACS_CORE)
      
       # Change Charter
        dataset$CHARTER[is.na(dataset$CHARTER)] <- 0
        dataset$CHARTER[dataset$CHARTER == "Y"] <- 1
        dataset$CHARTER[dataset$CHARTER == "D"] <- 2
        #change Year Round
        dataset$YR_RND[is.na(dataset$YR_RND)] <- 2
        dataset$YR_RND[dataset$YR_RND == "Yes"] <- 0
        dataset$YR_RND[dataset$YR_RND == "No"] <- 1

        #change to categorical
        dataset$CHARTER <- factor(dataset$CHARTER)
        dataset$YR_RND <- factor(dataset$YR_RND)
          
        #Change null values to 6
        dataset$AVG_ED[is.na(dataset$AVG_ED)] <- 6
        dataset$AVG_ED <- as.numeric(dataset$AVG_ED)
        dataset$AVG_ED <- round(dataset$AVG_ED, digits = 0)

        dataset$AVG_ED <- as.factor(dataset$AVG_ED)
        
        #Converting the Columns 
        dataset$API <- factor(dataset$API)
        dataset$VALID <- as.numeric(dataset$VALID)
        dataset$NUMTEACH <- as.numeric(dataset$NUMTEACH)
        dataset$FULL_PCT <- as.numeric(dataset$FULL_PCT)
        dataset$EMER_PCT <- as.numeric(dataset$EMER_PCT)
        dataset$WVR_PCT <- as.numeric(dataset$WVR_PCT)
        dataset$YRS_TEACH <- as.numeric(dataset$YRS_TEACH)
        dataset$YRONE_TCH <- as.numeric(dataset$YRONE_TCH)
        dataset$YRTWO_TCH <- as.numeric(dataset$YRTWO_TCH)
       
       return(dataset)
     }
 }

```

#####Transform Data
```{r}
elementary.reg = APITransform(elementary)
elementary.reg = ChangeCategorical(elementary.reg)

high.reg = APITransform(high)
high.reg = ChangeCategorical(high.reg)

middle.reg = APITransform(middle)
middle.reg = ChangeCategorical(middle.reg)
```

#####Test and Training Data
```{r}
#Elementary
set.seed(1)
train1 <- sample(1:nrow(elementary.reg), nrow(elementary.reg)/2)
elementary.train <- as.data.frame(elementary.reg[train1,])

test1 <- (-train1)
elementary.test <- elementary.reg[test1,]

#Middle
set.seed(1)
train2 <- sample(1:nrow(middle.reg), nrow(middle.reg)/2)
middleschool.train <- as.data.frame(middle.reg[train2,])

test2 <- (-train2)
middleschool.test <- middle.reg[test2,]

#High School
set.seed(1)
train3 <- sample(1:nrow(high.reg), nrow(high.reg)/2)
highschool.train <- as.data.frame(high.reg[train3,])

test3 <- (-train3)
highschool.test <- high.reg[test3,]

```
#####Class Metrics Function 
**Note: This metrics funtion is from homework 5**
```{r}
classMetrics <- function(score, y, cutoff, 
                         type = c("all", "accuracy", "sensitivity", 
                                  "specificity", "ppv", "npv", "precision", 
                                  "recall")) {
  type <- match.arg(type, several.ok = TRUE)
  n <- length(y) 
  
  # Form confusion matrix
  score.factor <- factor(as.numeric(score >= cutoff), levels = c("0", "1"))
  confusion.mat <- table(score.factor, as.factor(y), dnn = list("predicted", "observed"))

  # Calculate all metrics
  acc <- sum(diag(confusion.mat)) / n
  sens <- confusion.mat[2,2] / sum(confusion.mat[,2])
  spec <- confusion.mat[1,1] / sum(confusion.mat[,1])
  ppv <- confusion.mat[2,2] / sum(confusion.mat[2,])
  npv <- confusion.mat[1,1] / sum(confusion.mat[1,])
  prec <- ppv
  rec <- sens
  
  metric.names <- c("accuracy", "sensitivity", "specificity", 
                    "ppv", "npv", "precision", "recall")
  metric.vals <- c(acc, sens, spec, ppv, npv, prec, rec)
  
  # Form into data frame
  full.df <- data.frame(value = metric.vals)
  rownames(full.df) <- metric.names
  
  # Return just the requested subset of metrics
  if(type[1] == "all") {
    list(conf.mat = confusion.mat, perf = full.df)
  } else {
    list(conf.mat = confusion.mat, 
         perf = subset(full.df, subset = metric.names %in% type))
  }
}

plotClassMetrics <- function(score, y, xvar = NULL, yvar = c("accuracy", "sensitivity", 
                                  "specificity", "ppv", "npv", "precision", 
                                  "recall"),
                             flip.x = FALSE) {
  yvar <- match.arg(yvar)
  
  # If there are a lot of unique score values, just calculate the metrics
  # along an evenly spaced grid of 100 scores.
  unique.scores <- unique(score)
  if(length(unique.scores) > 100) {
    cutoff.seq <- sample(unique.scores, 100, replace = FALSE)
  } else {
    cutoff.seq <- unique.scores
  }
  
  n <- length(cutoff.seq)
  
  x.out <- numeric(n)
  y.out <- numeric(n)
  # Loop over all values of the score and calculate the performance metrics
  for(i in 1:n) {
    if(!is.null(xvar)) {
      metrics <- classMetrics(score, y, cutoff = cutoff.seq[i], type = c(xvar, yvar))
      x.out[i] <- metrics$perf[xvar, 1]
      y.out[i] <- metrics$perf[yvar, 1]
    } else {
      metrics <- classMetrics(score, y, cutoff = cutoff.seq[i], type = c(yvar))
      x.out[i] <- cutoff.seq[i]
      y.out[i] <- metrics$perf[yvar, 1]
    }
  }
  # Combine metrics into a data frame
  if(flip.x) {
    x.out <- 1 - x.out
  }
  df.out <- data.frame(score = cutoff.seq, x = x.out, y = y.out)
  # Reorder the data frame in increasing order of the x-axis variable
  df.out <- df.out[order(df.out$score), ]
  # De-duplicate x-axis
  df.out <- subset(df.out, subset = !duplicated(df.out$x))
  
  # Construct line plot
  if(!is.null(xvar)) {
    x.text <- ifelse(flip.x, paste0("1 - ", xvar), xvar)
  } else {
    x.text <- "score"
  }
  
  print(qplot(data = df.out, x = x, y = y, geom = "line",
              xlab = ifelse(is.null(xvar), "score", x.text),
              ylab = yvar, ylim = c(0, 1)))
}
```


### Models

####Logistic regressions
**In the following, we fit logistic regressions on all the grade level data separately (elementary school, middle school, and high school) and plotted API probability histograms**
##### Elementary School
```{r}
#Logistic regression 
elementary.log <- glm(API ~., family = binomial, data = elementary.reg) 
elemLog.summary <- summary(elementary.log)
kable(elemLog.summary$coefficients)

ggplot(elementary.reg, aes(elementary.log$fitted.values, fill = as.factor(elementary.log$y))) + geom_histogram() + labs(fill = "API", title = "Estimated API Probabilities Histogram", x = "Estimated API Probabilities") + theme_classic()

```

**For elementary school data, the variables that are statistically significant (p < 0.05) are Charter 2(negative), Valid(positive), AA_SIGYes(negative), AS_SIGYes(positive), WH_SIGYes(positive), SD_SIGYes(negative), YR_RND2(negative),ACS_CORE3(positive),AVG_ED3(positive),AVG_ED4(positive),AVG_ED5(positive), AVG_ED6(positive), NUMTEACH(negative), and YRTWO_TCH(negative).**
##### Middle School
```{r}
middle.log <- glm(API ~., family = binomial, data = middle.reg) 
kable(summary(middle.log)$coefficients )
ggplot(middle.reg, aes(middle.log$fitted.values, fill = as.factor(middle.log$y))) + geom_histogram() + labs(fill = "API", title = "Estimated API Probabilities Histogram", x = "Estimated API Probabilities") + theme_classic()
```

**Middle school data is slightly different. The variables that are statistically significant (p < 0.05) are Charter 2(positive), Valid(positive), AA_SIGYes(negative), AS_SIGYes(positive), WH_SIGYes(positive), NUMTEACH(negative), and FULL_PCT(positive). **
##### High School
```{r}
high.log <- glm(API ~., family = binomial, data = high.reg) 
kable(summary(high.log)$coefficients)
ggplot(high.reg, aes(high.log$fitted.values, fill = as.factor(high.log$y))) + geom_histogram() + labs(fill = "API", title = "Estimated API Probabilities Histogram", x = "Estimated API Probabilities") + theme_classic()
```

**High School Data also varies from the others.The variables that are statistically significant (p < 0.05) are Valid (positive), AA_SIGYes(negative), AS_SIGYes(positive), WH_SIGYes(positive), SD_SIGYes(positive),AVG_ED4(positive),AVG_ED6(positive), and NUMTEACH(negative).**
#### Forward Stepwise

**Note: How should we select the predictors? 1SE rule? Lowest BIC?**
##### Function
```{r}
forwardStepwise <- function(dataset,title){
  if(is.data.frame(dataset)){
    forward <- regsubsets(API~.,
                                    data=dataset, 
                                    nbest = 1, 
                                    nvmax = NULL, 
                                    method="forward", really.big=TRUE)
    # display variables in each model for the fist 12 models
    for(i in 1:12){
      co = coef(forward, id=i)
      print(i)
      print(co)
    }
    
    summary = summary(forward)
  
    # plot rsq on the y-axis
    plot(summary$rsq, xlab="model size", ylab="R-squared", type = "l",main = paste(title,"R-Squared", sep="\n"))
    # plot showing BIC on the y-axis and
    plot(summary$bic, xlab="Model Size", ylab="BIC",type = "l", main = paste(title,"BIC",sep="\n"))
    return(forward)
  }
}
```
##### Elementary School
```{r}
elem.stepWise <- forwardStepwise(elementary.reg, "Elementary School")
```
###### Model with Min BIC
```{r}
min.bic <- which.min(summary(elem.stepWise)$bic)
coef(elem.stepWise, min.bic)
```
##### Middle School
```{r}
middle.stepWise <- forwardStepwise(middle.reg,"Middle School")
```

###### Model with Min BIC
```{r}
min.bic <- which.min(summary(middle.stepWise)$bic)
coef(middle.stepWise, min.bic)
```
##### High School
```{r}
high.stepWise <- forwardStepwise(high.reg, "High School")
```
######Model with Min BIC
```{r}
min.bic <- which.min(summary(high.stepWise)$bic)
coef(high.stepWise, min.bic)
```

#### Lasso
#####Elementary
```{r}
#removing all rows where API is null
elementary.reg2 = elementary.reg

elem.x <- model.matrix(API~.,elementary.reg2)[,-1]
elem.y <- as.matrix(data.frame(elementary.reg$API))
#Need to change y to numeric to run cross validation
elem.y <- as.numeric(elem.y)

full <- data.frame(elem.x,elem.y)
# Split data into test and train
set.seed(1)
elem.train <- sample(1:nrow(elem.x), nrow(elem.x)/2)
e<-as.data.frame(elem.train)
elem.test <- (-elem.train)
elem.y.test <- elem.y[elem.test]

# If we want to specify the number of lambda values - not sure we actually need this
# Predefined grid of lambda values: 
# grid=10^seq(10,-2, length =100)

#lasso
elem.glm <- glmnet(elem.x[elem.train,],elem.y[elem.train],family = "binomial",alpha=1) 
elem.glm
#Plot the lasso
plot(elem.glm)

#Fit the model on our test data
set.seed(1)
elem.out=cv.glmnet(elem.x[elem.train,],elem.y[elem.train],alpha=1)
plot(elem.out)
```

######Determining coeffcients and significant predictors using lasso - Elementary
```{r,warning=FALSE}
#Figuring out the minimum lambda value and predicting CV error on test
elem.bestlam=elem.out$lambda.min
elem.1se=elem.out$lambda.1se
elem.lasso.pred=predict(elem.glm,s=elem.bestlam,newx=elem.x[elem.test,])
print("Minimum lambda for Elementary")
elem.bestlam
print("1SE lambda for Elementary")
elem.1se
print("CV Error for Elementary")
mean((elem.lasso.pred-elem.y.test)^2)

#Determine which variables are non-zero at the 1se value of lambda
out=glmnet(elem.x,elem.y,alpha=1,family="binomial")
elem.lasso.coef=predict(out,type="coefficients",s=elem.1se)
elem.lasso.coef
elem.lasso.coef[elem.lasso.coef!=0]
```



#####Middle School
```{r}
#removing all rows where API is null
middle.reg2 = middle.reg

middle.x <- model.matrix(API~.,middle.reg2)[,-1]
middle.y <- as.matrix(data.frame(middle.reg$API))
middle.y <- as.numeric(middle.y)

# Split data into test and train
set.seed(1)
middle.train <- sample(1:nrow(middle.x), nrow(middle.x)/2)
middle.test <- (-middle.train)
middle.y.test <- middle.y[middle.test]

# If we want to specify the number of lambda values - not sure we actually need this
# Predefined grid of lambda values: 
# grid=10^seq(10,-2, length =100)

#lasso
middle.glm <- glmnet(middle.x[middle.train,],middle.y[middle.train],family = "binomial",alpha=1) 
middle.glm
#Plot the lasso
plot(middle.glm)

set.seed(1)
middle.out=cv.glmnet(middle.x[middle.train,],middle.y[middle.train],alpha=1)
plot(middle.out)
```

######Determining coeffcients and significant predictors using lasso - Middle
```{r,warning= FALSE}
#Figuring out the minimum lambda value and predicting CV error on test
middle.bestlam=middle.out$lambda.min
middle.1se=middle.out$lambda.1se
middle.lasso.pred=predict(middle.glm,s=middle.bestlam,newx=middle.x[middle.test,])
print("Minimum lambda for Middle")
middle.bestlam
print("1SE lambda for Middle")
middle.1se
print("CV Error for Middle")
mean((middle.lasso.pred-middle.y.test)^2)

#Determine which variables are non-zero at the 1se value of lambda
out=glmnet(middle.x,middle.y,alpha=1,family="binomial")
middle.lasso.coef=predict(out,type="coefficients",s=middle.1se)
middle.lasso.coef
middle.lasso.coef[middle.lasso.coef!=0]
```


#####High School
```{r}
#removing all rows where API is null
high.reg2 = high.reg

high.x <- model.matrix(API~.,high.reg2)[,-1]
high.y <- as.matrix(data.frame(high.reg$API))
high.y <- as.numeric(high.y)

# Split data into test and train
set.seed(1)
high.train <- sample(1:nrow(high.x), nrow(high.x)/2)
high.test <- (-high.train)
high.y.test <- high.y[high.test]

# If we want to specify the number of lambda values - not sure we actually need this
# Predefined grid of lambda values: 
# grid=10^seq(10,-2, length =100)

#lasso
high.glm <- glmnet(high.x[high.train,],high.y[high.train],family = "binomial",alpha=1) 
high.glm
#Plot the lasso
plot(high.glm)

set.seed(1)
high.out=cv.glmnet(high.x[high.train,],high.y[high.train],alpha=1)
plot(high.out)
```
######Determining coeffcients and significant predictors using lasso - High
```{r}
#Figuring out the minimum lambda value and predicting CV error on test
high.bestlam=high.out$lambda.min
high.1se=high.out$lambda.1se
high.lasso.pred=predict(high.glm,s=high.bestlam,newx=high.x[high.test,])
print("Minimum lambda for High")
high.bestlam
print("1SE lambda for High")
high.1se
print("CV Error for High")
mean((high.lasso.pred-high.y.test)^2)

#Determine which variables are non-zero at the 1se value of lambda
out=glmnet(high.x,high.y,alpha=1,family="binomial")
high.lasso.coef=predict(out,type="coefficients",s=high.1se)
high.lasso.coef
high.lasso.coef[high.lasso.coef!=0]
```

####Classification with Naive Bayes
**Do we take this out?**

#####Elementary School
```{r, warning=FALSE}
elem.nb = NaiveBayes(elementary.reg$API ~ ., data = elementary.reg, usekernal = TRUE)
elem.nb.pred = predict(elem.nb,elementary.reg)
table(elem.nb.pred$class, elementary.reg$API)
cat("\n")
print("Misclassification Rate")
mean(elem.nb.pred$class != elementary.reg$API)

```
##### Middle School
```{r, warning=FALSE}
middle.nb = NaiveBayes(middle.reg$API ~ ., data = middle.reg, usekernal = TRUE)
middle.nb.pred = predict(middle.nb,middle.reg)
table(middle.nb.pred$class, middle.reg$API)
cat("\n")
print("Misclassification Rate")
mean(middle.nb.pred$class != middle.reg$API)

```
##### High School
```{r, warning=FALSE}
high.nb = NaiveBayes(high.reg$API ~ ., data = high.reg, usekernal = TRUE)
high.nb.pred = predict(high.nb,high.reg)
table(high.nb.pred$class, high.reg$API)
cat("\n")
print("Misclassification Rate")
mean(high.nb.pred$class != high.reg$API)

```

#### Decisions Trees
```{r}
treeFun <- function(dataset){
  tree <- rpart(API~.,data = dataset, method = "class")
  tree.party <- as.party(tree)
  plot(tree.party, gp = gpar(fontsize = 7))
  print(tree.party)
  return(tree)
}

treePruned <- function(tree){
   min.cv.idx <- which.min(tree$cptable[,"xerror"])
  # min CV error + 1se (this is the height of the horizontal bar)
  min.cv.err.1se <- tree$cptable[min.cv.idx,"xerror"] +
                   tree$cptable[min.cv.idx,"xstd"]
  # Which cp values produce models whose error is below min CV + 1se?
  cp.vals <- tree$cptable[which(tree$cptable[,"xerror"] < min.cv.err.1se),"CP"]

  # 1-SE rule value of cp
  cp.1se <- max(cp.vals)

  #Prune tree
  pruned.tree <- prune(tree, cp = cp.1se)
  tree.party<-as.party(pruned.tree)
  plot(tree.party, gp = gpar(fontsize = 7))
  print(tree.party)
  return(pruned.tree)
}
```
##### Elementary School Tree
```{r}
elementary.tree <- treeFun(elementary.train)
elementary.tree <- treePruned(elementary.tree)
```
**Just modeling the unpruned tree uses 3 distinct predictors. Pruning the tree based on 1SE rule narrows it down to one (Avg_Ed) **
######Elementary Confusion Matrix
```{r}
elem.test.prob <- predict(elementary.tree, newdata = elementary.test, type = "prob")[,"1"]
roc.elem <- roc(elementary.test$API, elem.test.prob)   
plot(roc.elem)
classMetrics(elem.test.prob, elementary.test$API, cutoff = 0.4)

```
##### Middle School Tree
```{r}
middle.tree <- treeFun(middleschool.train)
middle.tree <- treePruned(middle.tree)
```
###### Middle School Confusion Matrix
```{r}
middle.test.prob <- predict(middle.tree, newdata = middleschool.test, type = "prob")[,"1"]
roc.middle <- roc(middleschool.test$API, middle.test.prob)   
plot(roc.middle)
classMetrics(middle.test.prob, middleschool.test$API, cutoff = 0.4)
```
##### High School Tree
```{r}
high.tree <- treeFun(highschool.train)
high.tree <- treePruned(high.tree)

```
###### High School Confusion Matrix
```{r}
high.test.prob <- predict(high.tree, newdata = highschool.test, type = "prob")[,"1"]
roc.high <- roc(highschool.test$API, high.test.prob)   
plot(roc.high)
classMetrics(high.test.prob, highschool.test$API, cutoff = 0.4)
```

#### Random Forest
#####Elementary School
```{r}
elementary.train=elementary.train %>% mutate_if(is.character, as.factor)
elementary.test=elementary.test %>% mutate_if(is.character, as.factor)

elementary.rf <- randomForest(API~., data = elementary.train, mtry=4, importance=TRUE)
print(elementary.rf)
importance(elementary.rf)
varImpPlot(elementary.rf)
predict.elem <- predict(elementary.rf, newdata = elementary.test, type = "prob")[,1]

```


#####Middle School
```{r}
middleschool.train=middleschool.train %>% mutate_if(is.character, as.factor)
middle.rf <- randomForest(API~., data = middleschool.train, mtry=6, importance=TRUE)
print(middle.rf)
importance(middle.rf)
varImpPlot(middle.rf)
```

#####High School
```{r}
highschool.train=highschool.train %>% mutate_if(is.character, as.factor)
high.rf <- randomForest(API~., data = highschool.train, mtry=6, importance=TRUE)
print(high.rf)
importance(high.rf)
varImpPlot(high.rf)
```


##Results
** Insert answer here! **
*Item 1
*Item 2
  + Item 2.1
  + Item 2.2
  
# Question 2 - Do key determinants and their importance vary between school levels?
**Answer Here **

#Question 3 - Ethnic Factors and Their Importance

##Are ethnic factors significant predictors of school performance? 
**Answer Here **

##Is Their importance consistent across school levels?
**Answer Here ** 

#Question 4 - Could discrepancies in performance be reduced by actively reallocating teachers’ body?
**Answer here**

#Data Limitations
*Item 1
*Item 2
  +Item 2.1
  +Item 2.2
